<!DOCTYPE html>
<html lang="en-us"><head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<meta name="generator" content="Hugo 0.87.0" />
	
	<link rel="icon" href="/images/logo.png">
	
	<title>Principal Component Analysis (PCA) | Chandan&#39;s Blog</title>
	
	

	<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Principal Component Analysis (PCA)"/>
<meta name="twitter:description" content="PCA is very useful tool in machine learning. When it comes to dimensionality reduction, PCA is one of the basic and mostly used tools by ML practitioners."/>

	<meta property="og:title" content="Principal Component Analysis (PCA)" />
<meta property="og:description" content="PCA is very useful tool in machine learning. When it comes to dimensionality reduction, PCA is one of the basic and mostly used tools by ML practitioners." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chandan5362.github.io/glossary/pca/" /><meta property="article:section" content="glossary" />
<meta property="article:published_time" content="2021-09-02T17:46:41+05:30" />
<meta property="article:modified_time" content="2021-09-02T17:46:41+05:30" />


	
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DNTXE8FETV"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-DNTXE8FETV', { 'anonymize_ip': false });
}
</script>

	<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">

	
	<link rel="stylesheet" href="https://chandan5362.github.io/css/medium.98d43930037e4c96205af1c1a4de962c93b9f3545039e164e8533ecd5cd340ce.css" integrity="sha256-mNQ5MAN&#43;TJYgWvHBpN6WLJO581RQOeFk6FM&#43;zVzTQM4=">

	
	<link rel="stylesheet" href="https://chandan5362.github.io/css/additional.8819b6defcdc6d21280f9b402b00df87ca779135901de6c22e708c62e20184b9.css" integrity="sha256-iBm23vzcbSEoD5tAKwDfh8p3kTWQHebCLnCMYuIBhLk=">

	
	
	<script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$','$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  
    window.addEventListener('load', (event) => {
        document.querySelectorAll("mjx-container").forEach(function(x){
          x.parentElement.classList += 'has-jax'})
      });
  
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">
    <div class="container pr-0">
        
        <a class="navbar-brand" href="https://chandan5362.github.io//">

            
            <img src="/images/logo.png" alt="logo">
            
        </a>
        

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent"
            aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        
        <div class="collapse navbar-collapse" id="navbarMediumish">
            
            <ul class="navbar-nav ml-auto">
                 
                <li class="nav-item ">
                    <a class="nav-link" href="/blog">Blog</a>
                </li>
                 
                <li class="nav-item ">
                    <a class="nav-link" href="/">About Me</a>
                </li>
                 
                <li class="nav-item ">
                    <a class="nav-link" href="/glossary">ML Glossary</a>
                </li>
                 
                <li class="nav-item ">
                    <a class="nav-link" href="/static/portfolio">Portfolio</a>
                </li>
                 
                <li class="nav-item ">
                    <a class="nav-link" href="/static/updates">Updates</a>
                </li>
                
            </ul>
        </div>
        
    </div>
</nav>


        <div class="site-content">   
            <div class="container">
<div class="mainheading">
    <h1 class="sitetitle">Chandan&#39;s Blog</h1>
    <p class="lead">
         Geek&#39;s recharge pointü§ñ
    </p>
</div><div class="main-content">
        
        <div class="container">
            <div class="row">
                
                <div class="col-md-2 pl-0"><div class="share sticky-top sticky-top-offset">
    <p>Share</p>
    <ul>
        <li class="ml-1 mr-1">
        <a target="_blank" href="https://twitter.com/intent/tweet?text=Principal%20Component%20Analysis%20%28PCA%29&url=https%3a%2f%2fchandan5362.github.io%2fglossary%2fpca%2f" onclick="window.open(this.href, 'twitter-share', 'width=550,height=435');return false;">
        <i class="fab fa-twitter"></i>
        </a>
        </li>
        
        <li class="ml-1 mr-1">
        <a target="_blank" href="https://facebook.com/sharer.php?u=https%3a%2f%2fchandan5362.github.io%2fglossary%2fpca%2f" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
        <i class="fab fa-facebook-f"></i>
        </a>
        </li>

        <li class="ml-1 mr-1">
        <a target="_blank" href="https://www.xing.com/spi/shares/new?url=https%3a%2f%2fchandan5362.github.io%2fglossary%2fpca%2f" onclick="window.open(this.href, 'xing-share', 'width=550,height=435');return false;">
        <i class="fab fa-xing"></i>
        </a>
        </li>        
    </ul>

    
        <div class="sep">
        </div>				
        <ul>
            <li> 
            <a  class="small smoothscroll" href="#disqus_thread"></a>
            </li>
        </ul>
    
</div>
</div>
                                
                <div class="col-md-9 flex-first flex-md-unordered">
                    <div class="mainheading">
                        	
                        
                        
                        
                        <div class="row post-top-meta">
                            <div class="col-xs-12 col-md-3 col-lg-2 text-center text-md-left mb-4 mb-md-0 md-nopad-right">
                                <img class="author-thumb" src="/images/author.png" alt="Chandan Kumar Roy">
                            </div>
                            <div class="col-xs-12 col-md-9 col-lg-10 text-center text-md-left md-nopad-left">
                                <a target="_blank" class="link-dark">Chandan Kumar Roy</a><br>
                                <span class="author-description">
                                    Author of this blog.<br>
                                    <i class="far fa-star"></i>
                                    Sep 2, 2021
                                    <i class="far fa-clock clock"></i>
                                    3 min read
                                </span>					
                            </div>
                        </div>			
                        	
                        
                                                
                        
                        <h1 class="posttitle">Principal Component Analysis (PCA)</h1> 
                    </div>

                    
                    
                    
                    

                    
                    <div class="article-post">
                        <p>PCA is very useful tool in machine learning. When it comes to dimensionality reduction, PCA is one of the basic and mostly used tools by ML practitioners. PCA is linear combination of variables which best explains the data.Theoretical explanation can be found <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">here</a>.</p>
<h4 id="some-assumptions-that-are-used-in-pca">Some assumptions that are used in PCA:</h4>
<ul>
<li><strong>Linearity:</strong>  pca is linear combination of variables.</li>
<li><strong>Large variance implies more information:</strong> The direction of high variance accounts for most of the information in the dataset.</li>
<li><strong>Orthogonality:</strong> principal components are orthogonal to each other.</li>
</ul>
<div style="text-align: center;"><h4>PCA in Pythonüêç</h4></div>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
<span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
<span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> StandardScaler
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># toy dataset (n_rows= 1000, n_cols =15 )</span>
x_toy <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>random(size <span style="color:#f92672">=</span>(<span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">15</span>))
x_toy<span style="color:#f92672">.</span>shape
</code></pre></div><p>output:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-txt" data-lang="txt">(1000, 15)
</code></pre></div><h3 id="important-points">Important Points</h3>
<ol>
<li>eigen vectors corresponding to highest eigen vector
contains most of the variance in the dataset, second eigen value contains the second highest variance in the dataset and so on.</li>
<li>eigen vectors represent the linear combination of original feature vectors.</li>
<li>Eigen vectors do not change their directions, when linear rotation(scaling) is applied to them.</li>
</ol>
<h3 id="steps-">Steps :</h3>
<ol>
<li>
<p>Sandardizing (if the scale of the data is not uniform).</p>
</li>
<li>
<p>Zero center the data (substract the mean value)</p>
</li>
<li>
<p>find the covariance matrix.</p>
</li>
<li>
<p>find the eigen values and eigen vectors.</p>
</li>
<li>
<p>sort the eigen values and corresponding eigen vectors in descending order of eigen values.</p>
</li>
<li>
<p>retain the first <code>k</code> components of sorted eigen values to meet the <code>k</code> new feature dimension requirement.</p>
</li>
<li>
<p>project the original datapoints onto the line in the direction of eigen vectors.</p>
</li>
</ol>
<p>Let&rsquo;s see these steps one by one.</p>
<h5 id="1-standardization">1. Standardization</h5>
<p>Since our data already follows a uniform scale, Let&rsquo;s not do that here.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x_scaled <span style="color:#f92672">=</span> StandardScaler()<span style="color:#f92672">.</span>fit_transform(x_toy) 
</code></pre></div><p><strong>2.</strong> <strong>Zero centering</strong></p>
<p>Mean centering ensures that the first component is proportional to the direction of maximum variance.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x_toy <span style="color:#f92672">=</span> x_t <span style="color:#f92672">-</span> x_t<span style="color:#f92672">.</span>mean(axis <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>)
</code></pre></div><h5 id="2-covariance-matrix">2. covariance matrix</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># covariance matrix dimension: (n_clos, n_cols)</span>
n_cols <span style="color:#f92672">=</span> <span style="color:#ae81ff">15</span>
cov <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>cov(x_toy, rowvar <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>, bias <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>)
<span style="color:#66d9ef">assert</span> cov<span style="color:#f92672">.</span>shape <span style="color:#f92672">==</span> (n_cols, n_cols)
</code></pre></div><br>
<h5 id="3-eigen-values-and-eigen-vectors">3. eigen values and eigen vectors</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">eig_val, eig_vect <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linalg<span style="color:#f92672">.</span>eig(cov)
eig_val<span style="color:#f92672">.</span>shape, eig_vect<span style="color:#f92672">.</span>shape
</code></pre></div><p>output:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-txt" data-lang="txt"> ((15,), (15, 15))
</code></pre></div><p>There are 15 eigen values and corresponding to each eigen value, there is an eigen vector of shape (1, 15) e.i. for each <code>eig_val[i]</code>, there is an eigen vector <code>eig_vect[:, i]</code>.
<br></p>
<h5 id="4-sorting-in-descending-order-of-eigen-values">4. sorting in descending order of eigen values</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">indices <span style="color:#f92672">=</span> [i <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(eig_val))]

<span style="color:#75715e">#sort the index of eig_val in descending order</span>
indices<span style="color:#f92672">.</span>sort(key <span style="color:#f92672">=</span> eig_val[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>__getitem__, reverse<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)

<span style="color:#75715e">#sorted eigen vectors</span>
sorted_eig_vect <span style="color:#f92672">=</span> eig_vect[:, indices]

<span style="color:#75715e">#sorted eigen values</span>
sorted_eig_val <span style="color:#f92672">=</span> eig_val[indices]
</code></pre></div><br>
<h5 id="5-select-first-k-eigen-values-and-eigen-vectors">5. Select first k eigen values and eigen vectors</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">k <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
k_eigen_vals <span style="color:#f92672">=</span> sorted_eig_val[:<span style="color:#ae81ff">2</span>]
k_eigen_vectors <span style="color:#f92672">=</span> sorted_eig_vect[:, :<span style="color:#ae81ff">2</span>]
</code></pre></div><br>
<h5 id="6-projection-of-original-datapoints-along-the-principal-axis">6. Projection of original datapoints along the principal axis</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">new_dataset <span style="color:#f92672">=</span> x_toy<span style="color:#f92672">.</span>dot(k_eigen_vectors)
new_dataset<span style="color:#f92672">.</span>shape
</code></pre></div><p>output:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-txt" data-lang="txt">(1000, 2)
</code></pre></div><p>Voila! You have just learnt PCAü•≥</p>
<p>Since, PCA is fairly old technique, there are some drawbacks.<br>
<strong>Drawbacks:</strong></p>
<ul>
<li>It assumes the linear combination of features, which is not always true for every datasets.</li>
<li>Some information is lost. Even though it does not cause much loss in the actual outcome, sometimes, it can be bothering if you are working on very sensitive issue like medical diagnostic.</li>
<li>It is sensitive to the scaling of variables.</li>
</ul>
<hr>
<p>Happy learningüìñ<br>
keep smilingüòä</p>

                    </div>
                    
                    
                    <div class="after-post-tags">
                        <ul class="tags">
                        
                        <li>
                        <a href="/tags/statistics">statistics</a>
                        </li>
                        
                        <li>
                        <a href="/tags/machine-learning">machine learning</a>
                        </li>
                        
                        <li>
                        <a href="/tags/linear-algebra">linear-algebra</a>
                        </li>
                        
                        </ul>
                    </div>
                    
                    
                    
                    <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
                    
                        <a class="d-block col-md-6" href="https://chandan5362.github.io/glossary/bvt/"> &laquo; Bias and Variance Trade-off</a>
                    
                    
                    <div class="clearfix"></div>
                    </div>
                    
                </div>
                
            </div>
        </div>
        
        
<div class="container">
    <div id="comments" class="row justify-content-center mb-5">
        <div class="col-md-8">              
            <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "chandan5362" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>               
        </div>
    </div>
</div>

    </div>


            </div>
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
			<div class="d-md-flex align-items-center justify-content-center h-100">
				<h2 class="d-md-block d-none align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">‚Üí</span></h2>
			</div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
			
			<a class="mt-1 mb-1" href="/tags/data-science">data-science</a>
			
			<a class="mt-1 mb-1" href="/tags/linear-algebra">linear-algebra</a>
			
			<a class="mt-1 mb-1" href="/tags/machine-learning">machine-learning</a>
			
			<a class="mt-1 mb-1" href="/tags/statistics">statistics</a>
			
		</div>
	</div>
</div>

<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                &copy; Copyright Chandan Roy - All rights reserved
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">    
                <a target="_blank" rel="noopener" href="https://www.wowthemes.net">Mediumish Theme</a> by WowThemes.net
            </div>
        </div>
    </div>

      
</footer>




        </div>


<script src="https://code.jquery.com/jquery-3.4.1.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>


<script src="https://chandan5362.github.io/js/mediumish.84218587c174fd40bce82544b98851670f0b124a7324b349c54a4065e2b32ffc.js" integrity="sha256-hCGFh8F0/UC86CVEuYhRZw8LEkpzJLNJxUpAZeKzL/w="></script>
    </body>
</html>
